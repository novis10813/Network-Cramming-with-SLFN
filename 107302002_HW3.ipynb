{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from TrainingAlgorithm import TrainingAlgo\n",
    "from DataPreprocess import create_dataloader\n",
    "from model import TwoLayerNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def All_r_LG_UA_w_LG_UA(model=None,\n",
    "                        reg_params=None,\n",
    "                        weight_params=None,\n",
    "                        l2_lambda=0.001,\n",
    "                        l1_lambda=0.001,\n",
    "                        k=1,\n",
    "                        p=50):\n",
    "    \n",
    "    prune_index = 0\n",
    "    \n",
    "    while not k>p:\n",
    "        prune_index = random.randint(0, 127)\n",
    "        \n",
    "        train_algo.multiclass_regularization(epochs=reg_params['epochs'],\n",
    "                                            model=model,\n",
    "                                            optimizer=reg_params['optimizer'],\n",
    "                                            loss_threshold=reg_params['loss_threshold'],\n",
    "                                            eta_threshold=reg_params['eta_threshold'],\n",
    "                                            l2_lambda=l2_lambda,\n",
    "                                            l1_lambda=l1_lambda)\n",
    "        \n",
    "        saved_model = copy.deepcopy(model)\n",
    "        \n",
    "        model.del_neuron(index=prune_index)\n",
    "        \n",
    "        situation = train_algo.multiclass_weight_tuning(epochs=weight_params['epochs'],\n",
    "                                                        model=model,\n",
    "                                                        optimizer=weight_params['optimizer'],\n",
    "                                                        loss_threshold=weight_params['loss_threshold'],\n",
    "                                                        eta_threshold=weight_params['eta_threshold'])\n",
    "        \n",
    "        if situation == 'Unacceptable':\n",
    "            print('All : Restore Network')\n",
    "            model = saved_model\n",
    "            print(model)\n",
    "            k += 1\n",
    "        \n",
    "        elif situation == 'Acceptable':\n",
    "            print('Pruning Works!')\n",
    "            print(model)\n",
    "            p -= 1\n",
    "    \n",
    "    print('finish training')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------initializing regularization--------\n",
      "max loss:0.9177491664886475 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.67646, train_acc = 0.58073, val_loss = 0.43659, val_acc = 0.82292\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.61967, train_acc = 0.67188, val_loss = 0.63233, val_acc = 0.73958\n",
      "[ 2/10 ] | train_loss = 0.61833, train_acc = 0.67188, val_loss = 0.51566, val_acc = 0.77083\n",
      "[ 3/10 ] | train_loss = 0.60966, train_acc = 0.66406, val_loss = 0.47327, val_acc = 0.75000\n",
      "[ 4/10 ] | train_loss = 0.60754, train_acc = 0.70052, val_loss = 0.71947, val_acc = 0.75000\n",
      "[ 5/10 ] | train_loss = 0.59417, train_acc = 0.68490, val_loss = 0.61813, val_acc = 0.75000\n",
      "learning rate < threshold\n",
      "[ 6/10 ] | train_loss = 0.62200, train_acc = 0.63021, val_loss = 0.67192, val_acc = 0.72917\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7360213398933411 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59325, train_acc = 0.70312, val_loss = 0.55593, val_acc = 0.76042\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.64847, train_acc = 0.64062, val_loss = 0.70200, val_acc = 0.72917\n",
      "[ 2/10 ] | train_loss = 0.64294, train_acc = 0.64323, val_loss = 0.55611, val_acc = 0.75000\n",
      "[ 3/10 ] | train_loss = 0.62139, train_acc = 0.69010, val_loss = 0.61741, val_acc = 0.75000\n",
      "[ 4/10 ] | train_loss = 0.60927, train_acc = 0.65365, val_loss = 0.50569, val_acc = 0.72917\n",
      "[ 5/10 ] | train_loss = 0.60896, train_acc = 0.66667, val_loss = 0.67460, val_acc = 0.71875\n",
      "learning rate < threshold\n",
      "[ 6/10 ] | train_loss = 0.62928, train_acc = 0.65365, val_loss = 0.58937, val_acc = 0.73958\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8413125872612 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59764, train_acc = 0.70573, val_loss = 0.56122, val_acc = 0.80208\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.64777, train_acc = 0.64583, val_loss = 0.95721, val_acc = 0.76042\n",
      "[ 2/10 ] | train_loss = 0.62820, train_acc = 0.65625, val_loss = 0.66965, val_acc = 0.76042\n",
      "[ 3/10 ] | train_loss = 0.62750, train_acc = 0.68490, val_loss = 0.64325, val_acc = 0.76042\n",
      "[ 4/10 ] | train_loss = 0.61852, train_acc = 0.65885, val_loss = 0.62390, val_acc = 0.77083\n",
      "[ 5/10 ] | train_loss = 0.60957, train_acc = 0.67708, val_loss = 0.65543, val_acc = 0.75000\n",
      "[ 6/10 ] | train_loss = 0.60632, train_acc = 0.68229, val_loss = 0.58517, val_acc = 0.76042\n",
      "[ 7/10 ] | train_loss = 0.59968, train_acc = 0.70312, val_loss = 0.40688, val_acc = 0.76042\n",
      "learning rate < threshold\n",
      "[ 8/10 ] | train_loss = 0.64086, train_acc = 0.67188, val_loss = 0.58140, val_acc = 0.76042\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8159075379371643 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59921, train_acc = 0.68490, val_loss = 0.54900, val_acc = 0.79167\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.61868, train_acc = 0.68229, val_loss = 0.80022, val_acc = 0.78125\n",
      "[ 2/10 ] | train_loss = 0.61489, train_acc = 0.67188, val_loss = 0.44179, val_acc = 0.73958\n",
      "[ 3/10 ] | train_loss = 0.60744, train_acc = 0.69531, val_loss = 0.63530, val_acc = 0.76042\n",
      "[ 4/10 ] | train_loss = 0.59719, train_acc = 0.68490, val_loss = 0.63081, val_acc = 0.72917\n",
      "learning rate < threshold\n",
      "[ 5/10 ] | train_loss = 0.61532, train_acc = 0.69010, val_loss = 0.78747, val_acc = 0.76042\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.771253764629364 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.60751, train_acc = 0.69531, val_loss = 0.69231, val_acc = 0.79167\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.63440, train_acc = 0.62760, val_loss = 0.60645, val_acc = 0.75000\n",
      "[ 2/10 ] | train_loss = 0.63032, train_acc = 0.64323, val_loss = 0.56795, val_acc = 0.75000\n",
      "[ 3/10 ] | train_loss = 0.62235, train_acc = 0.67448, val_loss = 0.56913, val_acc = 0.71875\n",
      "learning rate < threshold\n",
      "[ 4/10 ] | train_loss = 0.63169, train_acc = 0.65885, val_loss = 0.68641, val_acc = 0.73958\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7797372341156006 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.57884, train_acc = 0.72396, val_loss = 0.50140, val_acc = 0.84375\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.62240, train_acc = 0.68229, val_loss = 0.83292, val_acc = 0.75000\n",
      "[ 2/10 ] | train_loss = 0.60367, train_acc = 0.67708, val_loss = 0.43855, val_acc = 0.72917\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.62851, train_acc = 0.65625, val_loss = 0.57297, val_acc = 0.75000\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8657996654510498 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.58860, train_acc = 0.72656, val_loss = 0.53041, val_acc = 0.83333\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.62052, train_acc = 0.67188, val_loss = 0.42108, val_acc = 0.79167\n",
      "[ 2/10 ] | train_loss = 0.61598, train_acc = 0.67188, val_loss = 0.63946, val_acc = 0.73958\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.62369, train_acc = 0.67969, val_loss = 0.51965, val_acc = 0.73958\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7731576561927795 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.60038, train_acc = 0.67708, val_loss = 0.67982, val_acc = 0.84375\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.58597, train_acc = 0.70052, val_loss = 0.59704, val_acc = 0.78125\n",
      "[ 2/10 ] | train_loss = 0.56924, train_acc = 0.72135, val_loss = 0.65108, val_acc = 0.76042\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.58077, train_acc = 0.72135, val_loss = 0.48420, val_acc = 0.79167\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8396920561790466 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.58292, train_acc = 0.71615, val_loss = 0.56275, val_acc = 0.83333\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.61516, train_acc = 0.67969, val_loss = 0.62037, val_acc = 0.75000\n",
      "learning rate < threshold\n",
      "[ 2/10 ] | train_loss = 0.62478, train_acc = 0.66667, val_loss = 0.79586, val_acc = 0.75000\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8008678555488586 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.60637, train_acc = 0.70573, val_loss = 0.59988, val_acc = 0.77083\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.54909, train_acc = 0.76562, val_loss = 0.67040, val_acc = 0.80208\n",
      "learning rate < threshold\n",
      "[ 2/10 ] | train_loss = 0.57393, train_acc = 0.71875, val_loss = 0.51888, val_acc = 0.82292\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7853711843490601 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59685, train_acc = 0.67448, val_loss = 0.60054, val_acc = 0.82292\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.61043, train_acc = 0.67188, val_loss = 0.51209, val_acc = 0.78125\n",
      "[ 2/10 ] | train_loss = 0.60633, train_acc = 0.67969, val_loss = 0.64164, val_acc = 0.72917\n",
      "[ 3/10 ] | train_loss = 0.60058, train_acc = 0.68750, val_loss = 0.74290, val_acc = 0.72917\n",
      "learning rate < threshold\n",
      "[ 4/10 ] | train_loss = 0.63849, train_acc = 0.66406, val_loss = 0.55052, val_acc = 0.76042\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8755350112915039 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59570, train_acc = 0.69010, val_loss = 0.68599, val_acc = 0.76042\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.64504, train_acc = 0.61979, val_loss = 0.68801, val_acc = 0.68750\n",
      "[ 2/10 ] | train_loss = 0.64108, train_acc = 0.64583, val_loss = 0.70528, val_acc = 0.68750\n",
      "[ 3/10 ] | train_loss = 0.64036, train_acc = 0.64323, val_loss = 0.51704, val_acc = 0.69792\n",
      "[ 4/10 ] | train_loss = 0.62769, train_acc = 0.66927, val_loss = 0.65353, val_acc = 0.68750\n",
      "learning rate < threshold\n",
      "[ 5/10 ] | train_loss = 0.65130, train_acc = 0.61198, val_loss = 0.58760, val_acc = 0.69792\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.9384293556213379 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.58511, train_acc = 0.71615, val_loss = 0.59853, val_acc = 0.83333\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.61118, train_acc = 0.65625, val_loss = 0.60511, val_acc = 0.75000\n",
      "learning rate < threshold\n",
      "[ 2/10 ] | train_loss = 0.62810, train_acc = 0.66406, val_loss = 0.64560, val_acc = 0.75000\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8110339045524597 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.60204, train_acc = 0.70052, val_loss = 0.66983, val_acc = 0.79167\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.61802, train_acc = 0.68750, val_loss = 0.57608, val_acc = 0.76042\n",
      "[ 2/10 ] | train_loss = 0.59106, train_acc = 0.70052, val_loss = 0.49534, val_acc = 0.76042\n",
      "[ 3/10 ] | train_loss = 0.58857, train_acc = 0.70833, val_loss = 0.55047, val_acc = 0.75000\n",
      "learning rate < threshold\n",
      "[ 4/10 ] | train_loss = 0.59482, train_acc = 0.69010, val_loss = 0.57893, val_acc = 0.75000\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7324243783950806 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59689, train_acc = 0.69531, val_loss = 0.51626, val_acc = 0.82292\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.62887, train_acc = 0.64323, val_loss = 0.61645, val_acc = 0.68750\n",
      "learning rate < threshold\n",
      "[ 2/10 ] | train_loss = 0.63280, train_acc = 0.64583, val_loss = 0.70756, val_acc = 0.72917\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7984493374824524 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.58553, train_acc = 0.73438, val_loss = 0.67600, val_acc = 0.84375\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.64441, train_acc = 0.64583, val_loss = 0.48620, val_acc = 0.71875\n",
      "[ 2/10 ] | train_loss = 0.63202, train_acc = 0.65625, val_loss = 0.57150, val_acc = 0.70833\n",
      "[ 3/10 ] | train_loss = 0.62039, train_acc = 0.67188, val_loss = 0.53222, val_acc = 0.70833\n",
      "learning rate < threshold\n",
      "[ 4/10 ] | train_loss = 0.63130, train_acc = 0.61979, val_loss = 0.64682, val_acc = 0.70833\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7494086623191833 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.60284, train_acc = 0.69271, val_loss = 0.64589, val_acc = 0.77083\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.60158, train_acc = 0.70312, val_loss = 0.68864, val_acc = 0.77083\n",
      "[ 2/10 ] | train_loss = 0.57888, train_acc = 0.70833, val_loss = 0.68011, val_acc = 0.76042\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.60237, train_acc = 0.73958, val_loss = 0.53829, val_acc = 0.77083\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7636431455612183 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.58852, train_acc = 0.70573, val_loss = 0.76364, val_acc = 0.79167\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.58742, train_acc = 0.72135, val_loss = 0.41105, val_acc = 0.83333\n",
      "[ 2/10 ] | train_loss = 0.58475, train_acc = 0.75260, val_loss = 0.71929, val_acc = 0.80208\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.59845, train_acc = 0.71354, val_loss = 0.58064, val_acc = 0.80208\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8295187950134277 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59307, train_acc = 0.72396, val_loss = 0.54156, val_acc = 0.82292\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.63289, train_acc = 0.61979, val_loss = 0.49144, val_acc = 0.73958\n",
      "[ 2/10 ] | train_loss = 0.62230, train_acc = 0.66927, val_loss = 0.78664, val_acc = 0.73958\n",
      "[ 3/10 ] | train_loss = 0.62204, train_acc = 0.68750, val_loss = 0.51274, val_acc = 0.72917\n",
      "[ 4/10 ] | train_loss = 0.61667, train_acc = 0.66667, val_loss = 0.80949, val_acc = 0.72917\n",
      "learning rate < threshold\n",
      "[ 5/10 ] | train_loss = 0.62760, train_acc = 0.66667, val_loss = 0.63872, val_acc = 0.72917\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8980113863945007 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.60971, train_acc = 0.69010, val_loss = 0.58911, val_acc = 0.85417\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.61083, train_acc = 0.65885, val_loss = 0.60901, val_acc = 0.70833\n",
      "learning rate < threshold\n",
      "[ 2/10 ] | train_loss = 0.63600, train_acc = 0.63281, val_loss = 0.65197, val_acc = 0.77083\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8589849472045898 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.60269, train_acc = 0.71615, val_loss = 0.70485, val_acc = 0.79167\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.61518, train_acc = 0.67188, val_loss = 0.57508, val_acc = 0.78125\n",
      "[ 2/10 ] | train_loss = 0.59269, train_acc = 0.71354, val_loss = 0.58981, val_acc = 0.76042\n",
      "[ 3/10 ] | train_loss = 0.59168, train_acc = 0.71094, val_loss = 0.65618, val_acc = 0.76042\n",
      "[ 4/10 ] | train_loss = 0.58015, train_acc = 0.71354, val_loss = 0.39971, val_acc = 0.83333\n",
      "learning rate < threshold\n",
      "[ 5/10 ] | train_loss = 0.60913, train_acc = 0.69271, val_loss = 0.69213, val_acc = 0.80208\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.777209997177124 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59477, train_acc = 0.71094, val_loss = 0.56755, val_acc = 0.79167\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.62018, train_acc = 0.67708, val_loss = 0.68195, val_acc = 0.70833\n",
      "learning rate < threshold\n",
      "[ 2/10 ] | train_loss = 0.63489, train_acc = 0.63021, val_loss = 0.72987, val_acc = 0.71875\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7290091514587402 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59977, train_acc = 0.68229, val_loss = 0.46098, val_acc = 0.76042\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.64824, train_acc = 0.63802, val_loss = 0.52839, val_acc = 0.65625\n",
      "[ 2/10 ] | train_loss = 0.64523, train_acc = 0.65104, val_loss = 0.63123, val_acc = 0.65625\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.67215, train_acc = 0.60156, val_loss = 0.81048, val_acc = 0.66667\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8039708733558655 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.60035, train_acc = 0.72396, val_loss = 0.42385, val_acc = 0.79167\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.60574, train_acc = 0.70573, val_loss = 0.51169, val_acc = 0.75000\n",
      "learning rate < threshold\n",
      "[ 2/10 ] | train_loss = 0.61454, train_acc = 0.67448, val_loss = 0.72193, val_acc = 0.72917\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7826424241065979 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.58428, train_acc = 0.73958, val_loss = 0.77210, val_acc = 0.83333\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.60247, train_acc = 0.68750, val_loss = 0.57315, val_acc = 0.79167\n",
      "[ 2/10 ] | train_loss = 0.59697, train_acc = 0.71354, val_loss = 0.60292, val_acc = 0.83333\n",
      "[ 3/10 ] | train_loss = 0.58834, train_acc = 0.72135, val_loss = 0.61584, val_acc = 0.81250\n",
      "[ 4/10 ] | train_loss = 0.58696, train_acc = 0.69792, val_loss = 0.52507, val_acc = 0.81250\n",
      "[ 5/10 ] | train_loss = 0.58236, train_acc = 0.74479, val_loss = 0.51345, val_acc = 0.83333\n",
      "[ 6/10 ] | train_loss = 0.57412, train_acc = 0.75260, val_loss = 0.64836, val_acc = 0.79167\n",
      "[ 7/10 ] | train_loss = 0.57367, train_acc = 0.72656, val_loss = 0.40928, val_acc = 0.78125\n",
      "learning rate < threshold\n",
      "[ 8/10 ] | train_loss = 0.58974, train_acc = 0.70052, val_loss = 0.66553, val_acc = 0.78125\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7392854690551758 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.58393, train_acc = 0.69010, val_loss = 0.64283, val_acc = 0.83333\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.63064, train_acc = 0.67448, val_loss = 0.70959, val_acc = 0.73958\n",
      "[ 2/10 ] | train_loss = 0.60685, train_acc = 0.69531, val_loss = 0.60969, val_acc = 0.73958\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.61920, train_acc = 0.67448, val_loss = 0.70291, val_acc = 0.75000\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7781260013580322 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.57843, train_acc = 0.71875, val_loss = 0.74879, val_acc = 0.80208\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.60594, train_acc = 0.66667, val_loss = 0.46999, val_acc = 0.83333\n",
      "[ 2/10 ] | train_loss = 0.58847, train_acc = 0.66927, val_loss = 0.60238, val_acc = 0.82292\n",
      "[ 3/10 ] | train_loss = 0.58405, train_acc = 0.71094, val_loss = 0.44906, val_acc = 0.79167\n",
      "[ 4/10 ] | train_loss = 0.57851, train_acc = 0.72656, val_loss = 0.60462, val_acc = 0.77083\n",
      "learning rate < threshold\n",
      "[ 5/10 ] | train_loss = 0.59772, train_acc = 0.68750, val_loss = 0.64508, val_acc = 0.76042\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8096745610237122 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59678, train_acc = 0.71354, val_loss = 0.41067, val_acc = 0.82292\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.59011, train_acc = 0.70312, val_loss = 0.48142, val_acc = 0.77083\n",
      "[ 2/10 ] | train_loss = 0.58759, train_acc = 0.72917, val_loss = 0.63810, val_acc = 0.76042\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.59266, train_acc = 0.71875, val_loss = 0.51169, val_acc = 0.76042\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8990523219108582 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59580, train_acc = 0.70833, val_loss = 0.54158, val_acc = 0.83333\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.60466, train_acc = 0.68490, val_loss = 0.57236, val_acc = 0.77083\n",
      "learning rate < threshold\n",
      "[ 2/10 ] | train_loss = 0.63416, train_acc = 0.63802, val_loss = 0.50668, val_acc = 0.76042\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7358406186103821 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.57967, train_acc = 0.70312, val_loss = 0.46137, val_acc = 0.77083\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.61865, train_acc = 0.65885, val_loss = 0.48022, val_acc = 0.75000\n",
      "learning rate < threshold\n",
      "[ 2/10 ] | train_loss = 0.62441, train_acc = 0.65365, val_loss = 0.51841, val_acc = 0.77083\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7521652579307556 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.57386, train_acc = 0.72396, val_loss = 0.55736, val_acc = 0.78125\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.60512, train_acc = 0.66146, val_loss = 0.68179, val_acc = 0.75000\n",
      "[ 2/10 ] | train_loss = 0.58554, train_acc = 0.70312, val_loss = 0.52611, val_acc = 0.73958\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.60230, train_acc = 0.68750, val_loss = 0.60668, val_acc = 0.75000\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8052888512611389 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.58261, train_acc = 0.70833, val_loss = 0.59973, val_acc = 0.77083\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.62503, train_acc = 0.66146, val_loss = 0.53484, val_acc = 0.76042\n",
      "[ 2/10 ] | train_loss = 0.61697, train_acc = 0.68750, val_loss = 0.66197, val_acc = 0.76042\n",
      "[ 3/10 ] | train_loss = 0.60985, train_acc = 0.69271, val_loss = 0.66335, val_acc = 0.76042\n",
      "learning rate < threshold\n",
      "[ 4/10 ] | train_loss = 0.61354, train_acc = 0.66406, val_loss = 0.58992, val_acc = 0.76042\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8425762057304382 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.57843, train_acc = 0.71615, val_loss = 0.54481, val_acc = 0.83333\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.62633, train_acc = 0.67708, val_loss = 0.65719, val_acc = 0.72917\n",
      "[ 2/10 ] | train_loss = 0.61833, train_acc = 0.66927, val_loss = 0.68683, val_acc = 0.71875\n",
      "[ 3/10 ] | train_loss = 0.61754, train_acc = 0.68229, val_loss = 0.56443, val_acc = 0.72917\n",
      "learning rate < threshold\n",
      "[ 4/10 ] | train_loss = 0.62331, train_acc = 0.67188, val_loss = 0.59204, val_acc = 0.72917\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8972158432006836 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59512, train_acc = 0.71354, val_loss = 0.61353, val_acc = 0.77083\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.59551, train_acc = 0.68750, val_loss = 0.71151, val_acc = 0.76042\n",
      "learning rate < threshold\n",
      "[ 2/10 ] | train_loss = 0.60578, train_acc = 0.68750, val_loss = 0.60542, val_acc = 0.77083\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8033455014228821 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.60334, train_acc = 0.70573, val_loss = 0.63242, val_acc = 0.77083\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.60249, train_acc = 0.67969, val_loss = 0.60949, val_acc = 0.77083\n",
      "[ 2/10 ] | train_loss = 0.58856, train_acc = 0.71354, val_loss = 0.62058, val_acc = 0.77083\n",
      "[ 3/10 ] | train_loss = 0.58190, train_acc = 0.73438, val_loss = 0.42617, val_acc = 0.81250\n",
      "[ 4/10 ] | train_loss = 0.57332, train_acc = 0.73958, val_loss = 0.53995, val_acc = 0.75000\n",
      "learning rate < threshold\n",
      "[ 5/10 ] | train_loss = 0.58555, train_acc = 0.71875, val_loss = 0.55771, val_acc = 0.76042\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7778095602989197 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.58697, train_acc = 0.71354, val_loss = 0.71989, val_acc = 0.83333\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.64193, train_acc = 0.63802, val_loss = 0.60528, val_acc = 0.63542\n",
      "[ 2/10 ] | train_loss = 0.62521, train_acc = 0.65625, val_loss = 0.59376, val_acc = 0.72917\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.64523, train_acc = 0.63542, val_loss = 0.64494, val_acc = 0.73958\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7793225646018982 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.58180, train_acc = 0.71354, val_loss = 0.39978, val_acc = 0.83333\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.62282, train_acc = 0.66406, val_loss = 0.89360, val_acc = 0.78125\n",
      "[ 2/10 ] | train_loss = 0.61778, train_acc = 0.69531, val_loss = 0.58279, val_acc = 0.77083\n",
      "[ 3/10 ] | train_loss = 0.61106, train_acc = 0.66667, val_loss = 0.61726, val_acc = 0.78125\n",
      "[ 4/10 ] | train_loss = 0.60889, train_acc = 0.67448, val_loss = 0.74076, val_acc = 0.76042\n",
      "[ 5/10 ] | train_loss = 0.60224, train_acc = 0.70833, val_loss = 0.51851, val_acc = 0.77083\n",
      "learning rate < threshold\n",
      "[ 6/10 ] | train_loss = 0.61781, train_acc = 0.67448, val_loss = 0.71226, val_acc = 0.79167\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8233732581138611 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.61435, train_acc = 0.67708, val_loss = 0.56912, val_acc = 0.77083\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.61975, train_acc = 0.67188, val_loss = 0.52372, val_acc = 0.76042\n",
      "[ 2/10 ] | train_loss = 0.60661, train_acc = 0.70833, val_loss = 0.50470, val_acc = 0.76042\n",
      "[ 3/10 ] | train_loss = 0.59510, train_acc = 0.72135, val_loss = 0.43759, val_acc = 0.77083\n",
      "[ 4/10 ] | train_loss = 0.58155, train_acc = 0.71875, val_loss = 0.52547, val_acc = 0.77083\n",
      "learning rate < threshold\n",
      "[ 5/10 ] | train_loss = 0.60728, train_acc = 0.66927, val_loss = 0.76116, val_acc = 0.76042\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8215210437774658 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59298, train_acc = 0.72656, val_loss = 0.64753, val_acc = 0.76042\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.59476, train_acc = 0.67969, val_loss = 0.66453, val_acc = 0.81250\n",
      "[ 2/10 ] | train_loss = 0.58436, train_acc = 0.70833, val_loss = 0.60420, val_acc = 0.76042\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.59388, train_acc = 0.71354, val_loss = 0.60414, val_acc = 0.79167\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7615030407905579 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.58380, train_acc = 0.70052, val_loss = 0.58159, val_acc = 0.79167\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.61834, train_acc = 0.64062, val_loss = 0.67964, val_acc = 0.73958\n",
      "[ 2/10 ] | train_loss = 0.60946, train_acc = 0.68750, val_loss = 0.56433, val_acc = 0.76042\n",
      "[ 3/10 ] | train_loss = 0.60275, train_acc = 0.70573, val_loss = 0.56527, val_acc = 0.76042\n",
      "learning rate < threshold\n",
      "[ 4/10 ] | train_loss = 0.61768, train_acc = 0.67969, val_loss = 0.76212, val_acc = 0.77083\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8222337365150452 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59351, train_acc = 0.72917, val_loss = 0.61701, val_acc = 0.79167\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.61578, train_acc = 0.66406, val_loss = 0.63701, val_acc = 0.73958\n",
      "[ 2/10 ] | train_loss = 0.60836, train_acc = 0.68490, val_loss = 0.67879, val_acc = 0.73958\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.62261, train_acc = 0.63542, val_loss = 0.42868, val_acc = 0.76042\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7228575348854065 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.57136, train_acc = 0.73438, val_loss = 0.59497, val_acc = 0.80208\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.63044, train_acc = 0.65104, val_loss = 0.59903, val_acc = 0.71875\n",
      "learning rate < threshold\n",
      "[ 2/10 ] | train_loss = 0.63257, train_acc = 0.63542, val_loss = 0.50839, val_acc = 0.71875\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7738538384437561 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.57812, train_acc = 0.71615, val_loss = 0.56572, val_acc = 0.80208\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.59363, train_acc = 0.70312, val_loss = 0.64981, val_acc = 0.77083\n",
      "[ 2/10 ] | train_loss = 0.58802, train_acc = 0.71094, val_loss = 0.84272, val_acc = 0.79167\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.62051, train_acc = 0.68750, val_loss = 0.55526, val_acc = 0.76042\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7498704195022583 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.58122, train_acc = 0.73177, val_loss = 0.72792, val_acc = 0.76042\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.62043, train_acc = 0.64323, val_loss = 0.51888, val_acc = 0.72917\n",
      "[ 2/10 ] | train_loss = 0.61886, train_acc = 0.66927, val_loss = 0.49415, val_acc = 0.72917\n",
      "[ 3/10 ] | train_loss = 0.60313, train_acc = 0.70052, val_loss = 0.68277, val_acc = 0.72917\n",
      "learning rate < threshold\n",
      "[ 4/10 ] | train_loss = 0.62266, train_acc = 0.64844, val_loss = 0.71077, val_acc = 0.73958\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7895656824111938 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59749, train_acc = 0.70312, val_loss = 0.75052, val_acc = 0.77083\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.63738, train_acc = 0.65104, val_loss = 0.64009, val_acc = 0.70833\n",
      "[ 2/10 ] | train_loss = 0.63461, train_acc = 0.63542, val_loss = 0.74478, val_acc = 0.69792\n",
      "[ 3/10 ] | train_loss = 0.63243, train_acc = 0.65625, val_loss = 0.45335, val_acc = 0.75000\n",
      "[ 4/10 ] | train_loss = 0.61931, train_acc = 0.66406, val_loss = 0.70790, val_acc = 0.69792\n",
      "learning rate < threshold\n",
      "[ 5/10 ] | train_loss = 0.61976, train_acc = 0.65365, val_loss = 0.70113, val_acc = 0.72917\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.8240950703620911 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.60044, train_acc = 0.69271, val_loss = 0.77297, val_acc = 0.80208\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.59781, train_acc = 0.68490, val_loss = 0.55534, val_acc = 0.81250\n",
      "[ 2/10 ] | train_loss = 0.58896, train_acc = 0.71094, val_loss = 0.60466, val_acc = 0.78125\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.59259, train_acc = 0.69531, val_loss = 0.42277, val_acc = 0.78125\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7755622267723083 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.57752, train_acc = 0.70312, val_loss = 0.56663, val_acc = 0.78125\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.61509, train_acc = 0.66927, val_loss = 0.69093, val_acc = 0.70833\n",
      "[ 2/10 ] | train_loss = 0.61263, train_acc = 0.68229, val_loss = 0.59005, val_acc = 0.71875\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.61659, train_acc = 0.68750, val_loss = 0.62512, val_acc = 0.69792\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.760598361492157 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.59162, train_acc = 0.71094, val_loss = 0.58945, val_acc = 0.84375\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.62180, train_acc = 0.65104, val_loss = 0.69625, val_acc = 0.71875\n",
      "[ 2/10 ] | train_loss = 0.61647, train_acc = 0.70312, val_loss = 0.72025, val_acc = 0.73958\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.62061, train_acc = 0.65625, val_loss = 0.80840, val_acc = 0.73958\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.7833362817764282 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.60189, train_acc = 0.70052, val_loss = 0.53351, val_acc = 0.83333\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.63722, train_acc = 0.59375, val_loss = 0.55343, val_acc = 0.68750\n",
      "learning rate < threshold\n",
      "[ 2/10 ] | train_loss = 0.64087, train_acc = 0.65104, val_loss = 0.58100, val_acc = 0.69792\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "--------initializing regularization--------\n",
      "max loss:0.743752121925354 > threshold0.6, stop training.\n",
      "[ 1 ] | train_loss = 0.57152, train_acc = 0.73958, val_loss = 0.56908, val_acc = 0.77083\n",
      "--------initializing weight tuning--------\n",
      "[ 1/10 ] | train_loss = 0.64861, train_acc = 0.63542, val_loss = 0.67240, val_acc = 0.64583\n",
      "[ 2/10 ] | train_loss = 0.63254, train_acc = 0.69010, val_loss = 0.70783, val_acc = 0.72917\n",
      "learning rate < threshold\n",
      "[ 3/10 ] | train_loss = 0.64489, train_acc = 0.63542, val_loss = 0.83900, val_acc = 0.72917\n",
      "All : Restore Network\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "finish training\n",
      "TwoLayerNN(\n",
      "  (layer_1): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TwoLayerNN(12, 128, 2, batch_norm=True, dropout=True)\n",
    "train_loader, val_loader = create_dataloader()\n",
    "\n",
    "# parameters for different task\n",
    "reg_optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "reg_loss_threshold = 0.6\n",
    "reg_eta_threshold = 1e-6\n",
    "reg_epochs = None\n",
    "\n",
    "weight_optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "weight_loss_threshold = 0.3\n",
    "weight_eta_threshold = 1e-6\n",
    "weight_epochs = 10\n",
    "\n",
    "reg = {'optimizer': reg_optimizer,\n",
    "       'loss_threshold': reg_loss_threshold,\n",
    "       'eta_threshold': reg_eta_threshold,\n",
    "       'epochs': reg_epochs}\n",
    "\n",
    "weight = {'optimizer': weight_optimizer,\n",
    "          'loss_threshold': weight_loss_threshold,\n",
    "          'eta_threshold': weight_eta_threshold,\n",
    "          'epochs': weight_epochs}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_algo = TrainingAlgo(train_loader, val_loader, criterion, device)\n",
    "model = All_r_LG_UA_w_LG_UA(model, reg, weight, l2_lambda=0.001, l1_lambda=0.001, p=50)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "219da6a50c866249bdfc07e8ee29701a3e2568a26ff21cc98a0eb284d1611ca6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
