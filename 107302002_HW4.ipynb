{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from DataPreprocess import create_dataloader\n",
    "from InitializingModule import InitModel\n",
    "from TrainingAlgorithm import LTS_module, multiclass_weight_tuning, reorganize_module, find_cram_index, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_mechanism(datapath:str,\n",
    "                       num_data:int,\n",
    "                       hidden_size:int,\n",
    "                       criterion,\n",
    "                       n:float,\n",
    "                       epochs:int,\n",
    "                       loss_threshold:float,\n",
    "                       eta_threshold:float,\n",
    "                       l_reg_params:dict,\n",
    "                       s_reg_params:dict,\n",
    "                       l_weight_params:dict,\n",
    "                       s_weight_params:dict):\n",
    "    '''\n",
    "    ### Args:\n",
    "        datapath: Where the data is.\n",
    "        num_data: The number of different ways separating training and validation data.\n",
    "        hidden_size: Init hidden layer size.\n",
    "        criterion: A pytorch loss function.\n",
    "        epochs: Epochs for weight-tuning module.\n",
    "        loss_threshold: loss_threshold for weight-tuning module.\n",
    "        eta_threshold: eta_threshold for weight-tuning module.\n",
    "        l_reg_params / s_reg_params: Parameters for regularizing module in reorganizing module.\n",
    "        l_weight_params / s_weight_params: Parameters for weight-tuning module in reorganizing module.\n",
    "    '''\n",
    "    \n",
    "    total_cram = []\n",
    "    total_param_bigger_than_n = []\n",
    "    total_weight_tuning = []\n",
    "    total_n_hidden_node = []\n",
    "    val_accuracy = []\n",
    "    train_accuracy = []\n",
    "    val_loss = []\n",
    "    train_loss = []\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for _ in range(num_data):\n",
    "        \n",
    "        cramming_times = 0\n",
    "        param_bigger_than_n_times = 0\n",
    "        weight_tuning_times = 0\n",
    "        \n",
    "        # Separate training set and validation set with random_state\n",
    "        train_loader, val_loader = create_dataloader(datapath, random_state=random.randint(0, 1440))\n",
    "        \n",
    "        N_data = train_loader.dataset.X.shape[0]\n",
    "        input_size = train_loader.dataset.X.shape[1]\n",
    "        \n",
    "        # initialize model\n",
    "        init_model = InitModel(input_size, hidden_size, 1, device)\n",
    "        model = init_model.init_module_multi_ReLU_AE(train_loader)\n",
    "        \n",
    "        # setting n for LTS module\n",
    "        n, _ = evaluate(train_loader, model, criterion, device)\n",
    "        n *= 0.7\n",
    "        \n",
    "        while N_data > n_data:\n",
    "            n_train_loader, n_data = LTS_module(train_loader=train_loader, model=model, criterion=criterion, n=n, device=device)\n",
    "            \n",
    "            param_num = sum(p.numel() for p in model.parameters())\n",
    "            \n",
    "            if n_data < param_num:\n",
    "                # Add reorganizing model (longer)\n",
    "                param_bigger_than_n_times += 1\n",
    "                model = reorganize_module(model, n_train_loader, val_loader, criterion, l_reg_params, l_weight_params)\n",
    "                continue\n",
    "            \n",
    "            saved_model = copy.deepcopy(model)\n",
    "            situation, model = multiclass_weight_tuning(n_train_loader, val_loader, epochs, model, criterion, loss_threshold, eta_threshold)\n",
    "            # model, situation = weight-tune\n",
    "            \n",
    "            if situation == 'Acceptable':\n",
    "                # Add reorganizing model (longer)\n",
    "                weight_tuning_times += 1\n",
    "                model = reorganize_module(model, n_train_loader, val_loader, criterion, l_reg_params, l_weight_params)\n",
    "                continue\n",
    "            \n",
    "            model = saved_model\n",
    "            \n",
    "            # cramming\n",
    "            cram_index = find_cram_index(model, n_train_loader, criterion, device)\n",
    "            model.add_neuron(n_train_loader, cram_index)\n",
    "            cramming_times += 1\n",
    "            \n",
    "            # Add reorganizing model (shorter)\n",
    "            model = reorganize_module(model, n_train_loader, val_loader, criterion, s_reg_params, s_weight_params)\n",
    "        \n",
    "        t_loss, t_accs = evaluate(train_loader, model, criterion, device)\n",
    "        v_loss, v_accs = evaluate(val_loader, model, criterion, device)\n",
    "        \n",
    "        total_cram.append(cramming_times)\n",
    "        total_param_bigger_than_n.append(param_bigger_than_n_times)\n",
    "        total_weight_tuning.append(weight_tuning_times)\n",
    "        total_n_hidden_node.append(model.layer_out.weight.numel())\n",
    "        train_accuracy.append(t_accs)\n",
    "        train_loss.append(t_loss)\n",
    "        val_accuracy.append(v_accs)\n",
    "        val_loss.append(v_loss)\n",
    "    \n",
    "    df = pd.DataFrame([total_cram, total_param_bigger_than_n, total_weight_tuning, total_n_hidden_node, train_accuracy, train_loss, val_accuracy, val_loss],\n",
    "                      columns=[f'{i}_data' for i in range(num_data)],\n",
    "                      index=['cram times', 'parameter bigger than n', 'weight tune', 'hidden node', 'train acc', 'train loss', 'val acc', 'val_loss'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "219da6a50c866249bdfc07e8ee29701a3e2568a26ff21cc98a0eb284d1611ca6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
